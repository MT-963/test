# ğŸ¯ Hybrid Model - AdÄ±m AdÄ±m DetaylÄ± AÃ§Ä±klama

## ASVspoof5 Deepfake Audio Detection

---

## ğŸ“Œ Model Ã–zeti

**Model AdÄ±:** WavLM + SSPS Hybrid (4x Downsampling)  
**AmaÃ§:** Sahte ses (deepfake audio) tespiti  
**Dataset:** ASVspoof5  
**En Ä°yi Eval EER:** 5.37%

---

## ğŸ”„ ADIM 1: Ses DosyasÄ±ndan Feature Ã‡Ä±karÄ±mÄ±

### 1.1 Ham Ses GiriÅŸi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HAM SES DOSYASI                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Input: audio.flac                                         â”‚
â”‚   Format: 16-bit PCM                                        â”‚
â”‚   Sample Rate: 16 kHz                                       â”‚
â”‚   Duration: ~3 saniye                                       â”‚
â”‚   Samples: 48,000 (3s Ã— 16,000)                             â”‚
â”‚                                                             â”‚
â”‚   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~              â”‚
â”‚   Dalga formu (waveform)                                    â”‚
â”‚   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 WavLM Feature Extraction

```python
# extract_wavlm.py - WavLM ile frame-level feature Ã§Ä±karÄ±mÄ±

# 1. WavLM LARGE modelini yÃ¼kle (Microsoft pre-trained)
bundle = torchaudio.pipelines.WAVLM_LARGE
model = bundle.get_model()

# 2. Ses dosyasÄ±nÄ± oku
waveform, sr = torchaudio.load("audio.flac")  # (1, 48000)

# 3. WavLM'den tÃ¼m katman Ã§Ä±ktÄ±larÄ±nÄ± al
with torch.no_grad():
    features, _ = model.extract_features(waveform)
    # features: List of 24 tensors, each (1, T, 1024)
    
# 4. 8. katmanÄ± seÃ§ (en iyi performans)
layer_8 = features[8]  # (1, 750, 1024)

# 5. Transpose: (1, 750, 1024) â†’ (1024, 750)
output = layer_8.squeeze(0).transpose(0, 1)  # (1024, 750)

# 6. 4x Downsample: temporal boyutu kÃ¼Ã§Ã¼lt
# 750 frames â†’ 187 frames (her 4 frame'den 1 tane)
output = output[:, ::4]  # (1024, 187)

# 7. Float16'ya dÃ¶nÃ¼ÅŸtÃ¼r (disk tasarrufu)
output = output.half()  # float32 â†’ float16

# 8. Kaydet
torch.save(output, "features/WAVLM/train/T_0000000001.pt")
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WavLM FEATURE EXTRACTION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Audio (48000 samples)                                     â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚   WavLM LARGE   â”‚  (317M parameters)                    â”‚
â”‚   â”‚   24 Layers     â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚   Layer 8 Output: (750, 1024)                               â”‚
â”‚   - 750 frames (20ms stride)                                â”‚
â”‚   - 1024 dimensions per frame                               â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼  4x Downsample                                 â”‚
â”‚   Final: (187, 1024)                                        â”‚
â”‚   - 187 frames (80ms stride)                                â”‚
â”‚   - float16 precision                                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 SSPS Feature Extraction

```python
# extractFeatures_SSPS_simple.py - SSPS ile utterance-level embedding

# 1. SSPS modelini yÃ¼kle (ECAPA-TDNN based, SimCLR trained)
checkpoint = torch.load("ssps_ecapa_vox2/model_avg.pt")
model = SimCLRModel(encoder_dim=512, channels=[1024,1024,1024,1024,3072])
model.load_state_dict(checkpoint)

# 2. Ses dosyasÄ±nÄ± oku ve mel-spectrogram'a dÃ¶nÃ¼ÅŸtÃ¼r
waveform, sr = torchaudio.load("audio.flac")
mel_spec = compute_mel_spectrogram(waveform)  # (80, T)

# 3. SSPS embedding Ã§Ä±kar
with torch.no_grad():
    embedding = model(mel_spec)  # (512,)
    
# 4. L2 normalize
embedding = F.normalize(embedding, dim=0)

# 5. Kaydet
torch.save(embedding, "features/SSPS/train/T_0000000001.pt")
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SSPS FEATURE EXTRACTION                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Audio (48000 samples)                                     â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚ Mel-Spectrogram â”‚  80 mel bands                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚   ECAPA-TDNN    â”‚  Speaker verification model           â”‚
â”‚   â”‚  (SimCLR pre-   â”‚  VoxCeleb2'de eÄŸitilmiÅŸ               â”‚
â”‚   â”‚   trained)      â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                â”‚
â”‚            â–¼                                                â”‚
â”‚   Utterance Embedding: (512,)                               â”‚
â”‚   - Tek vektÃ¶r (tÃ¼m ses iÃ§in)                               â”‚
â”‚   - Speaker characteristics                                  â”‚
â”‚   - L2 normalized                                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 2: Dataset YÃ¼kleme

### 2.1 Protocol DosyasÄ± Okuma

```python
# ASVspoof5.train.tsv formatÄ±:
# speaker_id  utt_id          gender  ...  label
# T_1234      T_0000000001    M       ...  bonafide
# T_5678      T_0000000002    F       ...  spoof

class HybridFeatureDataset(Dataset):
    def _read_protocol(self, path):
        # Protocol dosyasÄ±nÄ± parse et
        # uid_idx: utterance ID sÃ¼tunu (Ã¶rn: T_0000000001)
        # lab_idx: label sÃ¼tunu (bonafide/spoof)
        
        items = []
        for row in rows:
            uid = row[uid_idx]      # "T_0000000001"
            label = row[lab_idx]    # "bonafide" â†’ 0, "spoof" â†’ 1
            items.append((uid, label))
        return items
```

### 2.2 Feature YÃ¼kleme ve Padding

```python
def __getitem__(self, idx):
    utt_id, label = self.items[idx]
    
    # 1. WavLM feature yÃ¼kle
    w = torch.load(f"WAVLM/train/{utt_id}.pt")  # (1024, T)
    w = w.float()  # float16 â†’ float32
    w = self._pad(w)  # T'yi feat_len'e (187) eÅŸitle
    
    # 2. SSPS feature yÃ¼kle
    s = torch.load(f"SSPS/train/{utt_id}.pt")   # (512,)
    s = s.float()
    
    return w, s, utt_id, label
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LOADING PÄ°PELÄ°NE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Protocol File (TSV)                                       â”‚
â”‚        â”‚                                                    â”‚
â”‚        â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ (utt_id, label) pairs                       â”‚           â”‚
â”‚   â”‚ T_0000000001, 0 (bonafide)                  â”‚           â”‚
â”‚   â”‚ T_0000000002, 1 (spoof)                     â”‚           â”‚
â”‚   â”‚ ...                                         â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚        â–¼                               â–¼                    â”‚
â”‚   WavLM Feature                   SSPS Feature              â”‚
â”‚   (1024, 187)                     (512,)                    â”‚
â”‚        â”‚                               â”‚                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ Batch: (B, 1024, 187), (B, 512), labels     â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                             â”‚
â”‚   Train: 182,357 samples                                    â”‚
â”‚   Dev: 140,950 samples                                      â”‚
â”‚   Eval: 680,774 samples                                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 3: Model Mimarisi

### 3.1 WavLM Branch (Temporal Processing)

```python
class HybridModel(nn.Module):
    def __init__(self, wavlm_dim=1024, ssps_dim=512, emb_dim=256, feat_len=187):
        
        # WavLM Branch: Frame-level â†’ Utterance-level
        self.wavlm_backbone = NeXtTDNN(in_chans=1024)
        self.wavlm_pool = nn.AdaptiveAvgPool1d(1)
        self.wavlm_fc = nn.Linear(backbone_out_dim, 256)
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WavLM BRANCH (Temporal)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Input: WavLM Features (B, 1024, 187)                      â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚            NeXt-TDNN-ECA Backbone            â”‚           â”‚
â”‚   â”‚                                             â”‚           â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚           â”‚
â”‚   â”‚   â”‚ Conv1D + BatchNorm + ReLU           â”‚   â”‚           â”‚
â”‚   â”‚   â”‚ Temporal Dilation Layers            â”‚   â”‚           â”‚
â”‚   â”‚   â”‚ ECA (Efficient Channel Attention)   â”‚   â”‚           â”‚
â”‚   â”‚   â”‚ SE-Block (Squeeze-Excitation)       â”‚   â”‚           â”‚
â”‚   â”‚   â”‚ Res2Net-style Multi-scale           â”‚   â”‚           â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚   â”‚                                             â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   Backbone Output: (B, C', T')                              â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚     Adaptive Average Pooling 1D             â”‚           â”‚
â”‚   â”‚     (B, C', T') â†’ (B, C', 1) â†’ (B, C')      â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Linear Layer                      â”‚           â”‚
â”‚   â”‚           (C' â†’ 256)                        â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   Output: WavLM Embedding (B, 256)                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 SSPS Branch (Speaker Processing)

```python
        # SSPS Branch: Utterance-level processing
        self.ssps_fc = nn.Sequential(
            nn.Linear(512, 256),      # 512 â†’ 256
            nn.BatchNorm1d(256),      # Normalization
            nn.ReLU(inplace=True),    # Activation
        )
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SSPS BRANCH (Speaker)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Input: SSPS Features (B, 512)                             â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Linear Layer                      â”‚           â”‚
â”‚   â”‚           (512 â†’ 256)                       â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           BatchNorm1d(256)                  â”‚           â”‚
â”‚   â”‚           Feature normalization             â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           ReLU Activation                   â”‚           â”‚
â”‚   â”‚           max(0, x)                         â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   Output: SSPS Embedding (B, 256)                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Attention Fusion

```python
        # Attention-based Fusion
        self.attention = nn.Sequential(
            nn.Linear(512, 256),      # Concat(256, 256) = 512 â†’ 256
            nn.Tanh(),                # [-1, 1] range
            nn.Linear(256, 2),        # 2 attention weights
            nn.Softmax(dim=-1)        # Î± + Î² = 1
        )
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ATTENTION FUSION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   WavLM Emb (B, 256)          SSPS Emb (B, 256)             â”‚
â”‚        â”‚                           â”‚                        â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â”‚                                        â”‚
â”‚                    â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Concatenate                       â”‚           â”‚
â”‚   â”‚           (B, 256) + (B, 256) = (B, 512)    â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Linear (512 â†’ 256)                â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Tanh Activation                   â”‚           â”‚
â”‚   â”‚           Output: [-1, 1]                   â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Linear (256 â†’ 2)                  â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚                        â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚           Softmax                           â”‚           â”‚
â”‚   â”‚           [Î±, Î²] where Î± + Î² = 1            â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚                                    â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚          â”‚                           â”‚                      â”‚
â”‚          â–¼                           â–¼                      â”‚
â”‚      Î± (WavLM weight)           Î² (SSPS weight)             â”‚
â”‚          â”‚                           â”‚                      â”‚
â”‚          â–¼                           â–¼                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚   Fused = Î± Ã— WavLM_emb + Î² Ã— SSPS_emb      â”‚           â”‚
â”‚   â”‚   Output: (B, 256)                          â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                             â”‚
â”‚   Ã–RNEK:                                                    â”‚
â”‚   Î± = 0.6, Î² = 0.4                                          â”‚
â”‚   Fused = 0.6 Ã— WavLM + 0.4 Ã— SSPS                          â”‚
â”‚   â†’ Model, hangi bilginin daha Ã¶nemli olduÄŸunu Ã¶ÄŸrenir      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Classifier

```python
        # Final Classifier
        self.classifier = nn.Sequential(
            nn.Linear(256, 256),      # 256 â†’ 256
            nn.BatchNorm1d(256),      # Normalization
            nn.ReLU(inplace=True),    # Activation
            nn.Dropout(0.3),          # Regularization (30%)
            nn.Linear(256, 2),        # 256 â†’ 2 (bonafide/spoof)
        )
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLASSIFIER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Fused Embedding (B, 256)                                  â”‚
â”‚          â”‚                                                  â”‚
â”‚          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚          â”‚                                    â”‚             â”‚
â”‚          â–¼                                    â–¼             â”‚
â”‚   L2 Normalize                         Classifier           â”‚
â”‚   (for OC-Softmax)                          â”‚               â”‚
â”‚          â”‚                                  â”‚               â”‚
â”‚          â–¼                                  â–¼               â”‚
â”‚   Embedding (B, 256)               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   (unit norm)                      â”‚ Linear 256â†’256 â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚                â”‚
â”‚                                            â–¼                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                    â”‚  BatchNorm1d   â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚                â”‚
â”‚                                            â–¼                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                    â”‚     ReLU       â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚                â”‚
â”‚                                            â–¼                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                    â”‚  Dropout(0.3)  â”‚       â”‚
â”‚                                    â”‚  30% neurons   â”‚       â”‚
â”‚                                    â”‚  randomly off  â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚                â”‚
â”‚                                            â–¼                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                    â”‚ Linear 256â†’2   â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚                â”‚
â”‚                                            â–¼                â”‚
â”‚                                    Logits (B, 2)            â”‚
â”‚                                    [bonafide_score,         â”‚
â”‚                                     spoof_score]            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 4: Forward Pass (Tam AkÄ±ÅŸ)

```python
def forward(self, w: torch.Tensor, s: torch.Tensor):
    # w: WavLM features (B, 1024, 187)
    # s: SSPS features (B, 512)
    
    # ADIM 1: WavLM Branch
    w_out = self.wavlm_backbone(w)      # (B, C', T')
    w_out = self.wavlm_pool(w_out)      # (B, C', 1)
    w_out = w_out.squeeze(-1)           # (B, C')
    w_emb = self.wavlm_fc(w_out)        # (B, 256)
    
    # ADIM 2: SSPS Branch
    s_emb = self.ssps_fc(s)             # (B, 256)
    
    # ADIM 3: Attention Fusion
    concat = torch.cat([w_emb, s_emb], dim=-1)  # (B, 512)
    attn_weights = self.attention(concat)        # (B, 2)
    Î± = attn_weights[:, 0:1]                     # (B, 1)
    Î² = attn_weights[:, 1:2]                     # (B, 1)
    fused = Î± * w_emb + Î² * s_emb                # (B, 256)
    
    # ADIM 4: Output
    emb = F.normalize(fused, dim=1)     # L2 normalized embedding
    logits = self.classifier(fused)     # (B, 2)
    
    return emb, logits
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TAM MODEL AKIÅI                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   INPUT                                                                     â”‚
â”‚   â•â•â•â•â•                                                                     â”‚
â”‚   WavLM: (B, 1024, 187)                 SSPS: (B, 512)                      â”‚
â”‚        â”‚                                      â”‚                             â”‚
â”‚        â–¼                                      â–¼                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚  NeXt-TDNN-ECA   â”‚                 â”‚  Linear(512,256) â”‚                 â”‚
â”‚   â”‚    Backbone      â”‚                 â”‚  BatchNorm + ReLUâ”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚            â”‚                                    â”‚                           â”‚
â”‚            â–¼                                    â”‚                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚                           â”‚
â”‚   â”‚ Adaptive Pool    â”‚                          â”‚                           â”‚
â”‚   â”‚ + Linear(C',256) â”‚                          â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚                           â”‚
â”‚            â”‚                                    â”‚                           â”‚
â”‚            â–¼                                    â–¼                           â”‚
â”‚      WavLM_emb (B,256)                   SSPS_emb (B,256)                   â”‚
â”‚            â”‚                                    â”‚                           â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                           â”‚                                                 â”‚
â”‚                           â–¼                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚                    â”‚ Concatenate â”‚                                          â”‚
â”‚                    â”‚  (B, 512)   â”‚                                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                           â”‚                                                 â”‚
â”‚                           â–¼                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚                    â”‚  Attention  â”‚                                          â”‚
â”‚                    â”‚   [Î±, Î²]    â”‚                                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                           â”‚                                                 â”‚
â”‚                           â–¼                                                 â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚            â”‚ Fused = Î±Ã—WavLM + Î²Ã—SSPS     â”‚                                 â”‚
â”‚            â”‚         (B, 256)             â”‚                                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                           â”‚                                                 â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚            â”‚                              â”‚                                 â”‚
â”‚            â–¼                              â–¼                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚     â”‚ L2 Normalizeâ”‚               â”‚ Classifier  â”‚                           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚            â”‚                              â”‚                                 â”‚
â”‚            â–¼                              â–¼                                 â”‚
â”‚   OUTPUT                          OUTPUT                                    â”‚
â”‚   â•â•â•â•â•â•                          â•â•â•â•â•â•                                    â”‚
â”‚   Embedding (B, 256)              Logits (B, 2)                             â”‚
â”‚   (for OC-Softmax loss)           [bonafide_score, spoof_score]             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 5: Loss Hesaplama (OC-Softmax)

### 5.1 OC-Softmax MantÄ±ÄŸÄ±

```python
class OCSoftmax(nn.Module):
    def __init__(self, feat_dim=256, r_real=0.9, r_fake=0.2, alpha=20.0):
        self.center = nn.Parameter(torch.randn(1, feat_dim))  # Ã–ÄŸrenilebilir merkez
        self.r_real = r_real  # Bonafide iÃ§in hedef cosine similarity
        self.r_fake = r_fake  # Spoof iÃ§in hedef cosine similarity
        self.alpha = alpha    # Scaling factor
        
    def forward(self, x, labels):
        # x: Normalized embeddings (B, 256)
        # labels: 0=bonafide, 1=spoof
        
        # 1. Center'Ä± da normalize et
        w = F.normalize(self.center, dim=1)  # (1, 256)
        
        # 2. Cosine similarity hesapla
        scores = x @ w.T  # (B, 1) - her sample iÃ§in center'a benzerlik
        
        # 3. Loss hesapla
        # Bonafide (label=0): score >= r_real olmalÄ± (0.9'a yakÄ±n)
        # Spoof (label=1): score <= r_fake olmalÄ± (0.2'ye yakÄ±n)
        
        loss_scores = scores.clone()
        loss_scores[labels == 0] = r_real - scores[labels == 0]  # Bonafide
        loss_scores[labels == 1] = scores[labels == 1] - r_fake  # Spoof
        
        loss = softplus(alpha * loss_scores).mean()
        
        return loss, scores
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          OC-SOFTMAX LOSS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Embedding Space Visualization:                                            â”‚
â”‚                                                                             â”‚
â”‚                         â—                                                   â”‚
â”‚                        /â”‚\                                                  â”‚
â”‚                       / â”‚ \                                                 â”‚
â”‚                      /  â”‚  \                                                â”‚
â”‚                     /   â”‚   \                                               â”‚
â”‚                    /    â”‚    \                                              â”‚
â”‚                   /     â—     \  â† CENTER (Ã¶ÄŸrenilebilir)                   â”‚
â”‚                  /      â”‚      \                                            â”‚
â”‚                 /       â”‚       \                                           â”‚
â”‚                /        â”‚        \                                          â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚              -1         0         1                                         â”‚
â”‚                   Cosine Similarity                                         â”‚
â”‚                                                                             â”‚
â”‚   HEDEF:                                                                    â”‚
â”‚   â•â•â•â•â•â•â•                                                                   â”‚
â”‚   â€¢ Bonafide samples: score â‰¥ 0.9 (center'a yakÄ±n)                          â”‚
â”‚   â€¢ Spoof samples: score â‰¤ 0.2 (center'dan uzak)                            â”‚
â”‚                                                                             â”‚
â”‚   LOSS FORMÃœLÃœ:                                                             â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•                                                             â”‚
â”‚   Bonafide: loss = softplus(Î± Ã— (r_real - score))                           â”‚
â”‚             â†’ score < 0.9 ise loss yÃ¼ksek                                   â”‚
â”‚                                                                             â”‚
â”‚   Spoof:    loss = softplus(Î± Ã— (score - r_fake))                           â”‚
â”‚             â†’ score > 0.2 ise loss yÃ¼ksek                                   â”‚
â”‚                                                                             â”‚
â”‚   Ã–RNEK:                                                                    â”‚
â”‚   â•â•â•â•â•â•â•â•                                                                  â”‚
â”‚   Bonafide sample, score = 0.95: loss = softplus(20Ã—(0.9-0.95)) â‰ˆ 0        â”‚
â”‚   Bonafide sample, score = 0.50: loss = softplus(20Ã—(0.9-0.50)) â‰ˆ 8        â”‚
â”‚   Spoof sample, score = 0.10:    loss = softplus(20Ã—(0.10-0.2)) â‰ˆ 0        â”‚
â”‚   Spoof sample, score = 0.60:    loss = softplus(20Ã—(0.60-0.2)) â‰ˆ 8        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 6: Training Loop

```python
for epoch in range(100):
    model.train()
    
    # Learning rate decay (her 20 epoch'ta yarÄ±ya dÃ¼ÅŸÃ¼r)
    lr = base_lr * (0.5 ** (epoch // 20))
    
    for batch in train_loader:
        w, s, _, y = batch
        w, s, y = w.cuda(), s.cuda(), y.cuda()
        
        # Forward pass
        optimizer.zero_grad()
        emb, logits = model(w, s)
        
        # Loss hesapla (OC-Softmax)
        loss, _ = oc_softmax(emb, y)
        
        # Backward pass
        loss.backward()
        
        # Gradient clipping (stabilite iÃ§in)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        # Parameter update
        optimizer.step()
    
    # Validation
    model.eval()
    scores, labels = [], []
    for batch in dev_loader:
        w, s, _, y = batch
        emb, _ = model(w.cuda(), s.cuda())
        score, _ = oc_softmax(emb, y.cuda())
        scores.append(score)
        labels.append(y)
    
    # EER hesapla
    eer = compute_eer(bonafide_scores, spoof_scores)
    
    # En iyi modeli kaydet
    if eer < best_eer:
        save_model(model)
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRAINING TIMELINE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Epoch 1-20:   LR = 1e-4                                                   â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚   â†’ Model Ã¶ÄŸrenmeye baÅŸlar                                                  â”‚
â”‚   â†’ EER hÄ±zla dÃ¼ÅŸer: 50% â†’ 1%                                               â”‚
â”‚                                                                             â”‚
â”‚   Epoch 20-40:  LR = 5e-5 (decay)                                           â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚   â†’ Fine-tuning aÅŸamasÄ±                                                     â”‚
â”‚   â†’ EER stabilize olur: ~0.5%                                               â”‚
â”‚                                                                             â”‚
â”‚   Epoch 40+:    LR = 2.5e-5 (decay)                                         â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚   â†’ Micro-optimization                                                      â”‚
â”‚   â†’ Early stopping (20 epoch iyileÅŸme yoksa)                                â”‚
â”‚                                                                             â”‚
â”‚   EER Progression (4x DS Model):                                            â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                              â”‚
â”‚                                                                             â”‚
â”‚   EERâ”‚                                                                      â”‚
â”‚   1% â”œâ”€â”€â”€â”€*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚      â”‚      *                                                               â”‚
â”‚   0.5â”œâ”€â”€â”€â”€â”€â”€â”€*â”€â”€*â”€â”€â”€â”€â”€*â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚      â”‚              â†‘                                                       â”‚
â”‚   0% â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Epoch               â”‚
â”‚                   Best: 0.5171% (Epoch 15)                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ADIM 7: Inference (Test)

```python
# Test zamanÄ±
model.eval()
oc_softmax.eval()

with torch.no_grad():
    for audio_file in test_files:
        # 1. Feature extract
        wavlm_feat = extract_wavlm(audio_file)  # (1024, 187)
        ssps_feat = extract_ssps(audio_file)     # (512,)
        
        # 2. Model forward
        emb, _ = model(wavlm_feat, ssps_feat)
        
        # 3. Score hesapla (center'a cosine similarity)
        score = emb @ oc_softmax.center.T  # [-1, 1]
        
        # 4. Karar ver
        if score > threshold:  # threshold â‰ˆ 0.55 (EER noktasÄ±)
            prediction = "BONAFIDE (GerÃ§ek)"
        else:
            prediction = "SPOOF (Sahte)"
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           INFERENCE PÄ°PELÄ°NE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Yeni Ses DosyasÄ±                                                          â”‚
â”‚          â”‚                                                                  â”‚
â”‚          â–¼                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚   â”‚ 1. Feature Extraction                       â”‚                           â”‚
â”‚   â”‚    - WavLM: 750 frames â†’ 4x DS â†’ 187 frames â”‚                           â”‚
â”‚   â”‚    - SSPS: Utterance embedding              â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                        â”‚                                                    â”‚
â”‚                        â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚   â”‚ 2. Model Forward Pass                       â”‚                           â”‚
â”‚   â”‚    - WavLM branch: NeXt-TDNN â†’ 256-D        â”‚                           â”‚
â”‚   â”‚    - SSPS branch: Linear â†’ 256-D            â”‚                           â”‚
â”‚   â”‚    - Attention Fusion                       â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                        â”‚                                                    â”‚
â”‚                        â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚   â”‚ 3. Score Calculation                        â”‚                           â”‚
â”‚   â”‚    score = cosine(embedding, center)        â”‚                           â”‚
â”‚   â”‚    range: [-1, 1]                           â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                        â”‚                                                    â”‚
â”‚                        â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚   â”‚ 4. Decision                                 â”‚                           â”‚
â”‚   â”‚                                             â”‚                           â”‚
â”‚   â”‚    score > 0.55 â†’ BONAFIDE (GerÃ§ek Ses)     â”‚                           â”‚
â”‚   â”‚    score â‰¤ 0.55 â†’ SPOOF (Sahte Ses)         â”‚                           â”‚
â”‚   â”‚                                             â”‚                           â”‚
â”‚   â”‚    Ã–rnek Skorlar:                           â”‚                           â”‚
â”‚   â”‚    - GerÃ§ek ses: 0.91 â†’ BONAFIDE âœ“          â”‚                           â”‚
â”‚   â”‚    - TTS spoof:  -0.83 â†’ SPOOF âœ“            â”‚                           â”‚
â”‚   â”‚    - VC spoof:   -0.75 â†’ SPOOF âœ“            â”‚                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Model Parametreleri Ã–zeti

| BileÅŸen | Parametre SayÄ±sÄ± | Boyut |
|---------|------------------|-------|
| WavLM (frozen, sadece feature) | 317M | - |
| SSPS (frozen, sadece feature) | ~15M | - |
| NeXt-TDNN-ECA Backbone | ~2M | - |
| WavLM Pool + FC | ~50K | C' â†’ 256 |
| SSPS FC | ~130K | 512 â†’ 256 |
| Attention | ~130K | 512 â†’ 2 |
| Classifier | ~70K | 256 â†’ 2 |
| OC-Softmax Center | 256 | 1 Ã— 256 |
| **Toplam EÄŸitilebilir** | **~2.4M** | - |

---

## ğŸ¯ SonuÃ§

Bu hybrid model, iki farklÄ± bilgi kaynaÄŸÄ±nÄ± birleÅŸtirerek deepfake audio tespiti yapar:

1. **WavLM (Frame-level):** Temporal/spektral anomalileri yakalar
2. **SSPS (Utterance-level):** Speaker naturalness'Ä± deÄŸerlendirir
3. **Attention Fusion:** Hangi bilginin daha Ã¶nemli olduÄŸunu Ã¶ÄŸrenir
4. **OC-Softmax:** Tek sÄ±nÄ±flÄ± Ã¶ÄŸrenme ile robust decision boundary

**Final Performans:**
- Dev EER: 0.5171%
- Eval EER: 5.37%

---

**Rapor Tarihi:** 23 AralÄ±k 2024

